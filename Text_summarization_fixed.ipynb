{"cells":[{"cell_type":"markdown","metadata":{"id":"9inBm8oyr8E-"},"source":["Introduction: In this notebook, you will go through a method of how you can use generative models to summarize large documents."]},{"cell_type":"markdown","metadata":{"id":"t5UdnS4Qr9yX"},"source":["Install the required packeges: Vertex AI SDK, other packages and their dependencies"]},{"cell_type":"code","source":["%pip install google-cloud-aiplatform PyPDF2 ratelimit backoff --upgrade --quiet --user"],"metadata":{"id":"vQmAO2KB07BX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lWSqn1ykt2NK","outputId":"5261605a-8bcb-40a7-dd46-8ef2eb3c7c0b","executionInfo":{"status":"ok","timestamp":1740073905153,"user_tz":420,"elapsed":53,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'status': 'ok', 'restart': True}"]},"metadata":{},"execution_count":1}],"source":["# Automatically restart the kernel after installing packages\n","# to ensure the environment has access to newly installed dependencies.\n","\n","# Import the IPython module\n","import IPython\n","\n","# Get the current IPython application instance\n","app = IPython.Application.instance()\n","\n","# Forcefully restart the kernel to apply the changes\n","app.kernel.do_shutdown(restart=True)"]},{"cell_type":"markdown","metadata":{"id":"1V6P946zuqjP"},"source":["**Authenticating your notebook environment**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kKdTh2D7GTfR","outputId":"12867e55-511b-4fcf-9c9a-b09adbc7720d","executionInfo":{"status":"ok","timestamp":1740077319192,"user_tz":420,"elapsed":21115,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Go to the following link in your browser, and complete the sign-in prompts:\n","\n","    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=M1aRcmRwt3ZyDMQV2UhCdIWY9XcIKk&prompt=consent&token_usage=remote&access_type=offline&code_challenge=J-gxtwHE8t4f_fu_zGcTOEEEb7iSOHu6-MzuM1Iy-qQ&code_challenge_method=S256\n","\n","Once finished, enter the verification code provided in your browser: 4/0ASVgi3KSRlOrdWUoSs6rnhMvW5XS0ehjDsIpr6WYJIuLoVNgULacWdCe1kGj7NCIR6uwUg\n","\n","You are now logged in as [sfazeli@ualberta.ca].\n","Your current project is [tidal-datum-451517-i3].  You can change this setting by running:\n","  $ gcloud config set project PROJECT_ID\n"]}],"source":["!gcloud auth login"]},{"cell_type":"markdown","metadata":{"id":"QmCHTx6Au7H_"},"source":["**Import libraries**"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"nu9Ho--bu8cv","executionInfo":{"status":"ok","timestamp":1740077339198,"user_tz":420,"elapsed":2389,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[],"source":["import vertexai\n","\n","PROJECT_ID = \"tidal-datum-451517-i3\"  # Your Google Cloud Project ID\n","vertexai.init(project=PROJECT_ID, location=\"us-central1\")  # Initialize Vertex AI in the specified region"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"9S-nom2bvrrU","executionInfo":{"status":"ok","timestamp":1740078504526,"user_tz":420,"elapsed":1,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[],"source":["from pathlib import Path #\n","import urllib\n","import warnings\n","\n","import PyPDF2\n","import backoff\n","from google.api_core import exceptions\n","import ratelimit\n","from tqdm import tqdm\n","from vertexai.language_models import TextGenerationModel\n","import time\n","import ratelimit\n","from vertexai.preview.generative_models import GenerativeModel\n","\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"U-zlpe9EwjMW"},"source":["**Preparing data files**"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BbR5aRRfwkd8","outputId":"81edae67-8193-44f7-c295-5c32dfeffa84","executionInfo":{"status":"ok","timestamp":1740077788284,"user_tz":420,"elapsed":130,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(PosixPath('data/practitioners_guide_to_mlops_whitepaper.pdf'),\n"," <http.client.HTTPMessage at 0x7d42cedc7810>)"]},"metadata":{},"execution_count":21}],"source":["# To begin, it will be needed to download a pdf file for the summarizing tasks below.\n","# Define a folder to store the files\n","data_folder = \"data\"\n","Path(data_folder).mkdir(parents=True, exist_ok=True)\n","\n","#  Define a pdf link to download and place to store the download file\n","pdf_url = \"https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf\"\n","pdf_file = Path(data_folder, pdf_url.split(\"/\")[-1])\n","\n","# Download the file using `urllib` library\n","urllib.request.urlretrieve(pdf_url, pdf_file)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V7zheowfxQbV","outputId":"bd5fd8d6-332e-46d9-bc94-3d2cb3608998","executionInfo":{"status":"ok","timestamp":1740077791273,"user_tz":420,"elapsed":123,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Page 0: Practitioners guide to MLOps:  \n","A framework for continuous \n","delivery and automation of  \n","machine learning.White paper\n","May 2021\n","Authors:  \n","Khalid Salama,  \n","Jarek Kazmierczak,  \n","Donna Schut \n","\n","\n","Page 1: Table of Contents\n","Executive summary  3\n","Overview of MLOps lifecycle and core capabilities  4\n","Deep dive of MLOps processes  15\n","Putting it all together  34\n","Additional resources  36Building an ML-enabled system  6\n","The MLOps lifecycle  7\n","MLOps: An end-to-end workflow  8\n","MLOps capabilities  9\n","      Experimentation  11\n","      Data processing  11\n","      Model training  11\n","      Model evaluation  12\n","      Model serving  12\n","      Online experimentation  13\n","      Model monitoring  13\n","      ML pipelines  13\n","      Model registry  14\n","      Dataset and feature repository  14\n","      ML metadata and artifact tracking  15\n","ML development  16\n","Training operationalization  18\n","Continuous training  20\n","Model deployment  23\n","Prediction serving  25\n","Continuous monitoring  26\n","Data and model management  29\n","      Dataset and feature management  29\n","             Feature management  30\n","             Dataset management  31\n","      Model management  32\n","             ML metadata tracking  32\n","             Model governance  33 \n","\n","\n","Page 2: Executive summary\n","Across industries, DevOps and DataOps have been widely adopted as methodologies to improve quality and re -\n","duce the time to market of software engineering and data engineering initiatives. With the rapid growth in machine \n","learning (ML) systems, similar approaches need to be developed in the context of ML engineering, which handle the \n","unique complexities of the practical applications of ML. This is the domain of MLOps. MLOps is a set of standard -\n","ized processes and technology capabilities for building, deploying, and operationalizing ML systems rapidly and \n","reliably.]\n","We previously published Google Cloudâ€™s AI Adoption Framework  to provide guidance for technology leaders who \n","want to build an effective artificial intelligence (AI) capability in order to transform their business. That framework \n","covers AI challenges around people, data, technology, and process, structured in six different themes: learn, lead, \n","access, secure, scale, and automate . \n","The current document takes a deeper dive into the themes of scale  and automate  to illustrate the requirements for \n","building and operationalizing ML systems. Scale  concerns the extent to which you use cloud managed ML services \n","that scale with large amounts of data and large numbers of data processing and ML jobs, with reduced operational \n","overhead. Automate  concerns the extent to which you are able to deploy, execute, and operate technology for data \n","processing and ML pipelines in production efficiently, frequently, and reliably.\n","We outline an MLOps framework that defines core processes and technical capabilities. Organizations can use this \n","framework to help establish mature MLOps practices for building and operationalizing ML systems. Adopting the \n","framework can help organizations improve collaboration between teams, improve the reliability and scalability of ML \n","systems, and shorten development cycle times. These benefits in turn drive innovation and help gain overall busi -\n","ness value from investments in ML.\n","This document is intended for technology leaders and enterprise architects who want to understand MLOps. Itâ€™s also \n","for teams who want details about what MLOps looks like in practice. The document assumes that readers are famil -\n","iar with basic machine learning concepts and with development and deployment practices such as CI/CD.\n","The document is in two parts. The first part, an overview of the MLOps lifecycle, is for all readers. It introduces \n","MLOps processes and capabilities and why theyâ€™re important for successful adoption of ML-based systems.\n","The second part is a deep dive on the MLOps processes and capabilities. This part is for readers who want to un -\n","derstand the concrete details of tasks like running a continuous training pipeline, deploying a model, and monitoring \n","predictive performance of an ML model.3 \n","\n","\n"]}],"source":["# Read the PDF file and create a list of pages\n","reader = PyPDF2.PdfReader(pdf_file)\n","pages = reader.pages\n","\n","# Print three pages from the pdf\n","for i in range(3):\n","    text = pages[i].extract_text().strip()\n","    print(f\"Page {i}: {text} \\n\\n\")"]},{"cell_type":"markdown","metadata":{"id":"xwPjX7ayyFDu"},"source":["**Using Stuffing method**\n","\n","The most straightforward method for providing data to a language model is by embedding it directly into the prompt as context without using memory. This involves incorporating all relevant details within the prompt, arranged in the desired sequence for the model to process."]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zu8QqKuaxjHw","outputId":"1d03cce6-1930-4e0d-f22e-4c0377ccee62","executionInfo":{"status":"ok","timestamp":1740077797747,"user_tz":420,"elapsed":524,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:00<00:00, 87.97it/s]"]},{"output_type":"stream","name":"stdout","text":["There are 64758 characters in the pdf\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# Read the PDF file and create a list of pages\n","reader = PyPDF2.PdfReader(pdf_file)\n","pages = reader.pages\n","\n","# Entry string to concatenate all the extracted texts\n","concatenated_text = \"\"\n","\n","\n","# Loop through the pages\n","for page in tqdm(pages):\n","    # Extract the text from the page and remove any leading or trailing whitespace\n","    text = page.extract_text().strip()\n","\n","    # Concat the extracted text to the concatenated text\n","    concatenated_text += text\n","\n","print(f\"There are {len(concatenated_text)} characters in the pdf\")"]},{"cell_type":"markdown","metadata":{"id":"moDTce71zXAU"},"source":["**create a prompt template that can be used later in the notebook**"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"TjqDQdOSzYV7","executionInfo":{"status":"ok","timestamp":1740077806610,"user_tz":420,"elapsed":3,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[],"source":["prompt_template = \"\"\"\n","    Write a concise summary of the following text delimited by triple backquotes.\n","    Return your response in bullet points which covers the key points of the text.\n","\n","    ```{text}```\n","\n","    BULLET POINT SUMMARY:\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"0qBLHwfYzwnF"},"source":["**use LLM via the API to summarize the extracted texts**"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haJQvlpKzx4Q","outputId":"e2f02368-ada3-4cd5-d3e4-c44e1f6ec791","executionInfo":{"status":"ok","timestamp":1740077973852,"user_tz":420,"elapsed":9944,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["candidates {\n","  content {\n","    role: \"model\"\n","    parts {\n","      text: \"### MLOps: A framework for continuous delivery and automation of machine learning\\n\\n#### Overview\\n\\n* **MLOps** is a set of standardized processes and technology capabilities for building, deploying, and operationalizing ML systems rapidly and reliably.\\n* MLOps practices can result in shorter development cycles, better collaboration between teams, increased reliability, performance, scalability, and security of ML systems, streamlined operational and governance processes, and increased return on investment of ML projects.\\n* MLOps is an end-to-end workflow that encompasses seven integrated and iterative processes:\\n    * ML development\\n    * Training operationalization\\n    * Continuous training\\n    * Model deployment\\n    * Prediction serving\\n    * Continuous monitoring\\n    * Data and model management\\n\\n#### Key processes\\n\\n##### ML development\\n\\n* This is the core activity of MLOps, where data scientists and ML researchers develop and improve models.\\n* The primary output of this process is a formalized training procedure, which includes data preprocessing, model architecture, and model training settings.\\n* The key success factors for this process are experiment tracking, reproducibility, and collaboration.\\n\\n##### Training operationalization\\n\\n* This process involves building and testing a repeatable ML training pipeline and deploying it to a target execution environment.\\n* The pipeline typically goes through a series of testing and staging environments before being released to production.\\n* The specifics of the deployment process depend on the technology used to implement the pipeline.\\n\\n##### Continuous training\\n\\n* This process involves orchestrating and automating the execution of training pipelines.\\n* The frequency of retraining depends on the use case and the business value of doing so.\\n* Runs of the pipeline can be triggered in several ways, including scheduled runs, event-driven runs, and ad hoc runs.\\n\\n##### Model deployment\\n\\n* After a model has been trained, validated, and added to the model registry, it is ready for deployment.\\n* This process might involve a number of testing steps and testing environments.\\n* The model might need to go through a model governance process before it is allowed to be deployed to a target environment.\\n\\n##### Prediction serving\\n\\n* In this process, the model is deployed to its target environment and starts to accept prediction requests and serve responses with predictions.\\n* The serving engine can serve predictions to consumers in various forms, including online inference, streaming inference, offline batch inference, and embedded inference.\\n* An important part of having confidence in ML systems is being able to interpret the models and provide explanations to their predictions.\\n\\n##### Continuous monitoring\\n\\n* This process involves monitoring the effectiveness and efficiency of a model in production.\\n* It is essential to regularly and proactively verify that the model performance doesn\\'t decay.\\n* The monitoring engine uses the inference logs to identify anomalies, such as schema skews and distribution skews.\\n\\n##### Data and model management\\n\\n* This is a central function for governing ML artifacts in order to support auditability, traceability, and compliance, as well as shareability, reusability, and discoverability of ML assets.\\n* This includes dataset and feature management, model management, and ML metadata tracking.\\n\\n#### Conclusion\\n\\n* MLOps is a crucial methodology for organizations that want to harness the power of ML to improve their business operations.\\n* By implementing MLOps best practices, organizations can achieve significant benefits, including shorter development cycles, better collaboration, increased reliability and performance, and improved governance and risk management.\\n\"\n","    }\n","  }\n","  avg_logprobs: -0.23917269025530133\n","  finish_reason: STOP\n","  safety_ratings {\n","    category: HARM_CATEGORY_HATE_SPEECH\n","    probability: NEGLIGIBLE\n","    probability_score: 0.0427246094\n","    severity: HARM_SEVERITY_NEGLIGIBLE\n","    severity_score: 0.112792969\n","  }\n","  safety_ratings {\n","    category: HARM_CATEGORY_DANGEROUS_CONTENT\n","    probability: NEGLIGIBLE\n","    probability_score: 0.41796875\n","    severity: HARM_SEVERITY_LOW\n","    severity_score: 0.28515625\n","  }\n","  safety_ratings {\n","    category: HARM_CATEGORY_HARASSMENT\n","    probability: NEGLIGIBLE\n","    probability_score: 0.0952148438\n","    severity: HARM_SEVERITY_NEGLIGIBLE\n","    severity_score: 0.0549316406\n","  }\n","  safety_ratings {\n","    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n","    probability: NEGLIGIBLE\n","    probability_score: 0.0617675781\n","    severity: HARM_SEVERITY_LOW\n","    severity_score: 0.330078125\n","  }\n","  citation_metadata {\n","    citations {\n","      start_index: 113\n","      end_index: 244\n","      uri: \"https://computas.com/blogg/why-you-need-mlops-to-build-agile-ml-products/\"\n","    }\n","    citations {\n","      start_index: 281\n","      end_index: 417\n","      uri: \"https://www.enterpret.com/blog/basics-of-mlops\"\n","    }\n","    citations {\n","      start_index: 312\n","      end_index: 472\n","      uri: \"https://www.scribd.com/document/509789142/MLOps-Google-Cloud\"\n","    }\n","    citations {\n","      start_index: 583\n","      end_index: 775\n","      uri: \"https://ml-ops.org/content/model-governance\"\n","    }\n","    citations {\n","      start_index: 964\n","      end_index: 1110\n","      uri: \"https://www.scribd.com/document/509789142/MLOps-Google-Cloud\"\n","    }\n","    citations {\n","      start_index: 2084\n","      end_index: 2266\n","      uri: \"https://www.scribd.com/document/509789142/MLOps-Google-Cloud\"\n","    }\n","    citations {\n","      start_index: 2616\n","      end_index: 2749\n","      uri: \"https://www.scribd.com/document/509789142/MLOps-Google-Cloud\"\n","    }\n","    citations {\n","      start_index: 3097\n","      end_index: 3254\n","      uri: \"https://studylib.net/doc/25802529/practitioners-guide-to-mlops-whitepaper-google-cloud-1\"\n","    }\n","  }\n","}\n","model_version: \"gemini-1.0-pro-002\"\n","create_time {\n","  seconds: 1740077964\n","  nanos: 831764000\n","}\n","response_id: \"jHu3Z5TiMv-am9IP3prcsQY\"\n","usage_metadata {\n","  prompt_token_count: 13146\n","  candidates_token_count: 700\n","  total_token_count: 13846\n","  prompt_tokens_details {\n","    modality: TEXT\n","    token_count: 13146\n","  }\n","  candidates_tokens_details {\n","    modality: TEXT\n","    token_count: 700\n","  }\n","}\n","\n"]}],"source":["from vertexai.preview.generative_models import GenerativeModel\n","\n","# Load the Gemini model\n","generation_model = GenerativeModel(\"gemini-pro\")\n","\n","# Define the prompt using the prompt template\n","prompt = prompt_template.format(text=concatenated_text)\n","\n","# Use the model to summarize the text using the prompt\n","summary =  generation_model.generate_content([prompt])\n","print(summary)\n"]},{"cell_type":"code","source":["# Extract the summary text from the response\n","summary_text = summary.candidates[0].content.parts[0].text\n","\n","# Print the clean summary\n","print(summary_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EanAfNo5u-vL","executionInfo":{"status":"ok","timestamp":1740078055657,"user_tz":420,"elapsed":9,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}},"outputId":"1dc1b69c-8c7b-4ca8-de08-e141891e36a7"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["### MLOps: A framework for continuous delivery and automation of machine learning\n","\n","#### Overview\n","\n","* **MLOps** is a set of standardized processes and technology capabilities for building, deploying, and operationalizing ML systems rapidly and reliably.\n","* MLOps practices can result in shorter development cycles, better collaboration between teams, increased reliability, performance, scalability, and security of ML systems, streamlined operational and governance processes, and increased return on investment of ML projects.\n","* MLOps is an end-to-end workflow that encompasses seven integrated and iterative processes:\n","    * ML development\n","    * Training operationalization\n","    * Continuous training\n","    * Model deployment\n","    * Prediction serving\n","    * Continuous monitoring\n","    * Data and model management\n","\n","#### Key processes\n","\n","##### ML development\n","\n","* This is the core activity of MLOps, where data scientists and ML researchers develop and improve models.\n","* The primary output of this process is a formalized training procedure, which includes data preprocessing, model architecture, and model training settings.\n","* The key success factors for this process are experiment tracking, reproducibility, and collaboration.\n","\n","##### Training operationalization\n","\n","* This process involves building and testing a repeatable ML training pipeline and deploying it to a target execution environment.\n","* The pipeline typically goes through a series of testing and staging environments before being released to production.\n","* The specifics of the deployment process depend on the technology used to implement the pipeline.\n","\n","##### Continuous training\n","\n","* This process involves orchestrating and automating the execution of training pipelines.\n","* The frequency of retraining depends on the use case and the business value of doing so.\n","* Runs of the pipeline can be triggered in several ways, including scheduled runs, event-driven runs, and ad hoc runs.\n","\n","##### Model deployment\n","\n","* After a model has been trained, validated, and added to the model registry, it is ready for deployment.\n","* This process might involve a number of testing steps and testing environments.\n","* The model might need to go through a model governance process before it is allowed to be deployed to a target environment.\n","\n","##### Prediction serving\n","\n","* In this process, the model is deployed to its target environment and starts to accept prediction requests and serve responses with predictions.\n","* The serving engine can serve predictions to consumers in various forms, including online inference, streaming inference, offline batch inference, and embedded inference.\n","* An important part of having confidence in ML systems is being able to interpret the models and provide explanations to their predictions.\n","\n","##### Continuous monitoring\n","\n","* This process involves monitoring the effectiveness and efficiency of a model in production.\n","* It is essential to regularly and proactively verify that the model performance doesn't decay.\n","* The monitoring engine uses the inference logs to identify anomalies, such as schema skews and distribution skews.\n","\n","##### Data and model management\n","\n","* This is a central function for governing ML artifacts in order to support auditability, traceability, and compliance, as well as shareability, reusability, and discoverability of ML assets.\n","* This includes dataset and feature management, model management, and ML metadata tracking.\n","\n","#### Conclusion\n","\n","* MLOps is a crucial methodology for organizations that want to harness the power of ML to improve their business operations.\n","* By implementing MLOps best practices, organizations can achieve significant benefits, including shorter development cycles, better collaboration, increased reliability and performance, and improved governance and risk management.\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"1ReYwV0O39TZ"},"source":["The model returned an error message: \"400 Request contains an invalid argument\" due to the extracted text exceeding the processing limit of the generative model.\n","\n","To prevent this issue, you should input only a portion of the extracted text, such as the first 30,000 words."]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sm5IoxES4G7j","outputId":"624ab3c6-5130-40fa-b13a-2448dfee39b3","executionInfo":{"status":"ok","timestamp":1740078148598,"user_tz":420,"elapsed":4299,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["candidates {\n","  content {\n","    role: \"model\"\n","    parts {\n","      text: \"## MLOps: A Guide to Continuous Delivery and Automation of Machine Learning\\n\\n**Key Points:**\\n\\n**MLOps Lifecycle:**\\n\\n* **7 Integrated Processes:**\\n    * ML Development\\n    * Training Operationalization\\n    * Continuous Training\\n    * Model Deployment\\n    * Prediction Serving\\n    * Continuous Monitoring\\n    * Data and Model Management\\n* **Workflow:**\\n    * **Experimentation:** Data analysis, model prototyping, training procedures\\n    * **Data Processing:** Prepare and transform data for ML\\n    * **Model Training:** Run training algorithms efficiently\\n    * **Model Evaluation:** Assess model effectiveness\\n    * **Model Serving:** Deploy and serve models in production\\n    * **Online Experimentation:** Understand model performance before release\\n    * **Model Monitoring:** Track model performance in production\\n\\n**MLOps Capabilities:**\\n\\n* **Core Capabilities:**\\n    * Experimentation\\n    * Data Processing\\n    * Model Training\\n    * Model Evaluation\\n    * Model Serving\\n    * Online Experimentation\\n    * Model Monitoring\\n    * ML Pipelines\\n    * Model Registry\\n    * Dataset and Feature Repository\\n    * ML Metadata and Artifact Tracking\\n* **Foundational Capabilities:**\\n    * Compute Infrastructure\\n    * Configuration Management\\n    * CI/CD\\n\\n**Benefits of MLOps:**\\n\\n* Shorter development cycles\\n* Better collaboration between teams\\n* Increased reliability, performance, scalability, and security\\n* Streamlined operational and governance processes\\n* Increased return on investment\\n\\n**MLOps Adoption:**\\n\\n* **Gradual Implementation:** Start with key processes and capabilities\\n* **Alignment with Business Priorities:** Prioritize based on business needs\\n\\n**Key Success Factors:**\\n\\n* Experiment tracking\\n* Reproducibility\\n* Collaboration\\n* Integration with other MLOps capabilities\\n\\n**Additional Resources:**\\n\\n* Google Cloud AI Adoption Framework\\n\\n**Audience:**\\n\\n* Technology leaders and enterprise architects\\n* Teams involved in ML development and deployment\\n\\n**Assumptions:**\\n\\n* Readers have basic ML and development/deployment knowledge\"\n","    }\n","  }\n","  avg_logprobs: -0.25561841174996219\n","  finish_reason: STOP\n","  safety_ratings {\n","    category: HARM_CATEGORY_HATE_SPEECH\n","    probability: NEGLIGIBLE\n","    probability_score: 0.0952148438\n","    severity: HARM_SEVERITY_NEGLIGIBLE\n","    severity_score: 0.176757812\n","  }\n","  safety_ratings {\n","    category: HARM_CATEGORY_DANGEROUS_CONTENT\n","    probability: NEGLIGIBLE\n","    probability_score: 0.221679688\n","    severity: HARM_SEVERITY_LOW\n","    severity_score: 0.217773438\n","  }\n","  safety_ratings {\n","    category: HARM_CATEGORY_HARASSMENT\n","    probability: NEGLIGIBLE\n","    probability_score: 0.189453125\n","    severity: HARM_SEVERITY_NEGLIGIBLE\n","    severity_score: 0.0903320312\n","  }\n","  safety_ratings {\n","    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n","    probability: NEGLIGIBLE\n","    probability_score: 0.104980469\n","    severity: HARM_SEVERITY_LOW\n","    severity_score: 0.203125\n","  }\n","  citation_metadata {\n","    citations {\n","      start_index: 133\n","      end_index: 302\n","      uri: \"https://ml-ops.org/content/model-governance\"\n","    }\n","    citations {\n","      start_index: 874\n","      end_index: 1036\n","      uri: \"https://analyticsindiamag.com/mlops-for-dummies/\"\n","    }\n","    citations {\n","      start_index: 1277\n","      end_index: 1404\n","      uri: \"https://www.enterpret.com/blog/basics-of-mlops\"\n","    }\n","  }\n","}\n","model_version: \"gemini-1.0-pro-002\"\n","create_time {\n","  seconds: 1740078144\n","  nanos: 455218000\n","}\n","response_id: \"QHy3Z7LkG76Ym9IP-qGF4AY\"\n","usage_metadata {\n","  prompt_token_count: 6050\n","  candidates_token_count: 413\n","  total_token_count: 6463\n","  prompt_tokens_details {\n","    modality: TEXT\n","    token_count: 6050\n","  }\n","  candidates_tokens_details {\n","    modality: TEXT\n","    token_count: 413\n","  }\n","}\n","\n"]}],"source":["# Define the prompt using the prompt template\n","prompt = prompt_template.format(text=concatenated_text[:30000])\n","\n","# Use the model to summarize the text using the prompt\n","summary = generation_model.generate_content([prompt])\n","\n","print(summary)"]},{"cell_type":"markdown","metadata":{"id":"AfNQB9g6DtDs"},"source":["Summary\n","\n","Since the full text exceeds the model's capacity, it is successfully generated a concise, bulleted summary of key information from a portion of the PDF. Below are the advantages and limitations of the stuffing method:\n","Advantages:\n","\n","âœ” Requires only a single model call.\n","\n","âœ” The model processes all the provided data at once, which can lead to a higher-quality summary.\n","Limitations:\n","\n","âœ– Most models have a context length limit, making this method ineffective for large documents or multiple documents.\n","\n","âœ– Suitable only for small text segments, as it cannot efficiently handle extensive content.\n","\n","In the next session, alternative techniques will be exploreed to overcome the context length limitations of LLMs when dealing with longer texts."]},{"cell_type":"markdown","metadata":{"id":"FypaiCZMFdqu"},"source":["Adding Rate Limit to Model Calls\n","\n","When MapReduce or similar methods are used, multiple API calls are made to the model within a short period. However, there is a limit on the number of API calls allowed per minute, requiring a safety measure to be implemented in the code to prevent exceeding this limit. This ensures smooth execution and minimizes errors.\n","\n","For this approach, the following steps are taken:\n","\n","    A Python library called ratelimit is used to restrict the number of API calls per minute.\n","    A Python library called backoff is utilized to retry requests until the maximum time limit is reached.\n","\n","The function below optimizes the API call process by restricting the number of requests to 20 per minute. Additionally, it incorporates a backoff mechanism that retries the API call upon encountering a \"Resource Exhausted\" exception. The waiting period increases exponentially until the five-minute limit is reached, after which retry attempts are discontinued."]},{"cell_type":"code","execution_count":36,"metadata":{"id":"1BaP3KD8DuBl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740078545113,"user_tz":420,"elapsed":2422,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}},"outputId":"d65912ba-8683-4b24-efb4-32e976e5851e"},"outputs":[{"output_type":"stream","name":"stdout","text":["## Concise Summary:\n","\n","This white paper, titled \"Practitioner's Guide to MLOps: A Framework for Continuous Delivery and Automation of Machine Learning,\" provides guidance on implementing MLOps, a framework for automating and continuously delivering machine learning models. Authored by Khalid Salama, Jarek Kazmierczak, and Donna Schut, the paper was published in May 2021. \n","\n"]}],"source":["# Load the Gemini model\n","generation_model = GenerativeModel(\"gemini-pro\")\n","\n","# Define rate limit settings\n","CALL_LIMIT = 20  # Number of API calls allowed per minute\n","ONE_MINUTE = 60  # One minute in seconds\n","FIVE_MINUTE = 5 * ONE_MINUTE  # Max retry time (5 minutes)\n","\n","# Function to print messages when retrying due to rate limits\n","def backoff_hdlr(details):\n","    print(f\"Retrying in {details['wait']} seconds, attempt {details['tries']}...\")\n","\n","# Retry logic with exponential backoff\n","@backoff.on_exception(\n","    backoff.expo,  # Exponential backoff strategy\n","    (exceptions.ResourceExhausted, ratelimit.RateLimitException),  # Handle rate limits\n","    max_time=FIVE_MINUTE,  # Stop retrying after 5 minutes\n","    on_backoff=backoff_hdlr,  # Function to call when retrying\n",")\n","@ratelimit.limits(calls=CALL_LIMIT, period=ONE_MINUTE)  # Limit API calls per minute\n","def model_with_limit_and_backoff(prompt):\n","    \"\"\"Calls the Gemini model with rate limiting and retry handling.\"\"\"\n","    response = generation_model.generate_content([prompt])  # Fixed API call\n","    return response.text\n","\n","# Use the existing prompt\n","try:\n","    summary = model_with_limit_and_backoff(prompt)  # Use your pre-defined prompt\n","    print(summary)  # Print the generated summary\n","except Exception as e:\n","    print(f\"Error: {e}\")  # Handle unexpected errors\n"]},{"cell_type":"markdown","metadata":{"id":"baKxJomQIhMJ"},"source":["Method 2: MapReduce\n","\n","This approach involves dividing large data into smaller chunks and processing each chunk individually using a prompt. In summarization tasks, each chunk produces a summarized output. Once all the summaries are generated, a separate prompt is applied to merge them into a final summary.\n","\n","Although this method is more complex than the previous one, it is often more effective for handling large datasets. To implement this approach, two prompt templates are prepared:\n","\n","    One for generating summaries of individual chunks.\n","    Another for combining the summarized outputs."]},{"cell_type":"code","execution_count":37,"metadata":{"id":"4F53e8kQIht4","executionInfo":{"status":"ok","timestamp":1740078553951,"user_tz":420,"elapsed":39,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[],"source":["initial_prompt_template = \"\"\"\n","    Write a concise summary of the following text delimited by triple backquotes.\n","\n","    ```{text}```\n","\n","    CONCISE SUMMARY:\n","\"\"\"\n","\n","final_prompt_template = \"\"\"\n","    Write a concise summary of the following text delimited by triple backquotes.\n","    Return your response in bullet points which covers the key points of the text.\n","\n","    ```{text}```\n","\n","    BULLET POINT SUMMARY:\n","\"\"\"\n"]},{"cell_type":"markdown","metadata":{"id":"ZJzNMChaI0BQ"},"source":["**Map step**\n","\n","In this section, the PDF file will be reloaded, and the model will generate a summary for each page separately using the initial prompt template."]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iajm68I_IsjD","outputId":"adf71123-7ea8-46de-9550-85f164b72b23","executionInfo":{"status":"ok","timestamp":1740078771932,"user_tz":420,"elapsed":98756,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"stream","name":"stderr","text":[" 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 20/37 [00:47<00:41,  2.43s/it]INFO:backoff:Backing off model_with_limit_and_backoff(...) for 0.5s (ratelimit.exception.RateLimitException: too many calls)\n"]},{"output_type":"stream","name":"stdout","text":["Retrying in 0.4803064393578632 seconds, attempt 1...\n"]},{"output_type":"stream","name":"stderr","text":["INFO:backoff:Backing off model_with_limit_and_backoff(...) for 1.2s (ratelimit.exception.RateLimitException: too many calls)\n"]},{"output_type":"stream","name":"stdout","text":["Retrying in 1.1844697426212671 seconds, attempt 2...\n"]},{"output_type":"stream","name":"stderr","text":["INFO:backoff:Backing off model_with_limit_and_backoff(...) for 2.6s (ratelimit.exception.RateLimitException: too many calls)\n"]},{"output_type":"stream","name":"stdout","text":["Retrying in 2.612145751891835 seconds, attempt 3...\n"]},{"output_type":"stream","name":"stderr","text":["INFO:backoff:Backing off model_with_limit_and_backoff(...) for 6.8s (ratelimit.exception.RateLimitException: too many calls)\n"]},{"output_type":"stream","name":"stdout","text":["Retrying in 6.799675111144275 seconds, attempt 4...\n"]},{"output_type":"stream","name":"stderr","text":["INFO:backoff:Backing off model_with_limit_and_backoff(...) for 5.3s (ratelimit.exception.RateLimitException: too many calls)\n"]},{"output_type":"stream","name":"stdout","text":["Retrying in 5.3478317755874425 seconds, attempt 5...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [01:38<00:00,  2.67s/it]\n"]}],"source":["# Read the PDF file and create a list of pages\n","reader = PyPDF2.PdfReader(pdf_file)\n","pages = reader.pages\n","\n","# Create an empty list to store the summaries\n","initial_summary = []\n","\n","# Iterate over the pages and generate a summary for each page\n","for page in tqdm(pages):\n","    # Extract the text from the page and remove any leading or trailing whitespace\n","    text = page.extract_text().strip()\n","\n","    # Create a prompt for the model using the extracted text and a prompt template\n","    prompt = initial_prompt_template.format(text=text)\n","\n","    # Generate a summary using the model and the prompt\n","    summary = model_with_limit_and_backoff(prompt)\n","\n","    # Append the summary to the list of summaries\n","    initial_summary.append(summary)\n"]},{"cell_type":"markdown","metadata":{"id":"cWjj2qy6JZ-_"},"source":["\n","\n","Take a look at the first few summaries of from the initial Map phrase.\n"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sn_n4HM_JTTy","outputId":"0e8bedb3-e941-459d-953c-92b9c30faeec","executionInfo":{"status":"ok","timestamp":1740078866180,"user_tz":420,"elapsed":64,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ“œ **Extracted Summaries from PDF:**\n","\n","ðŸ“„ **Page 1 Summary:**\n","A guide to MLOps, a framework for continuous delivery and automation of machine learning. Authored by Khalid Salama, Jarek Kazmierczak, and Donna Schut in May 2021.\n","\n","--------------------------------------------------------------------------------\n","\n","ðŸ“„ **Page 2 Summary:**\n","## Concise Summary\n","\n","This document presents a comprehensive overview of **MLOps** (Machine Learning Operations) including its lifecycle, processes, and capabilities. It also covers essential components like ML Pipelines, Model Management, and Data Management.\n","\n","**Key Highlights:**\n","\n","* **MLOps Lifecycle:** Explains the different stages involved in deploying and managing ML models, from development to monitoring and prediction serving.\n","* **MLOps Capabilities:** Explores various capabilities enabling effective ML model development, including data processing, model training, evaluation, serving, monitoring, and continuous training.\n","* **ML Pipelines:** emphasizes the crucial role of pipelines in automating and streamlining the ML model development process.\n","* **Data and Model Management:** Discusses various aspects of data and model management, including dataset management, feature management, and model governance.\n","\n","\n","This document offers valuable insights and guidance for organizations seeking to successfully implement and manage ML models within their operations.\n","--------------------------------------------------------------------------------\n","\n","ðŸ“„ **Page 3 Summary:**\n","## Concise Summary\n","\n","This document provides an overview of MLOps, a set of practices for building and operationalizing machine learning (ML) systems. It focuses on the \"scale\" and \"automate\" aspects of Google Cloud's AI Adoption Framework, highlighting the importance of cloud-managed ML services and automation for efficient ML development and deployment. \n","\n","The document outlines an MLOps framework that defines core processes and technical capabilities, aiming to improve collaboration, reliability, scalability, and development cycle times for ML systems. This ultimately drives innovation and business value from ML investments. \n","\n","The document targets technology leaders, enterprise architects, and teams involved in building and deploying ML systems. It assumes familiarity with basic ML concepts and development/deployment practices like CI/CD. \n","\n","The first part offers an overview of the MLOps lifecycle, while the second part dives deeper into specific processes and capabilities for running continuous training pipelines, deploying models, and monitoring ML performance. \n","\n","--------------------------------------------------------------------------------\n","\n","ðŸ“„ **Page 4 Summary:**\n","## Concise Summary:\n","\n","This text discusses the challenges of deploying and operationalizing machine learning models at scale. \n","\n","**Key Points:**\n","\n","* Despite growing recognition of AI/ML's importance, many organizations struggle to move beyond pilot projects and deploy models in production.\n","* Common challenges include:\n","    * Lack of automation and streamlined processes.\n","    * High degree of manual work and non-reusable components.\n","    * Difficulties in handoffs between data scientists and IT.\n","    * Lack of mid- to senior-level talent and change management processes.\n","    * Absence of strong governance models for scaling.\n","* Organizations need to adopt and apply sound software engineering practices to operationalize ML effectively.\n","* Implementing an automated and streamlined ML process can help organizations successfully deploy models, manage risk, and ensure alignment with business goals.\n","\n","--------------------------------------------------------------------------------\n","\n","ðŸ“„ **Page 5 Summary:**\n","## Concise Summary\n","\n","This passage discusses the importance of ML engineering in building production-grade ML systems. It highlights the complexities involved in ML projects, including data preparation, performance monitoring, experimentation, and fairness concerns.\n","\n","MLOps is introduced as a methodology for unifying ML system development and operations. It provides standardized processes and technologies for building, deploying, and operationalizing ML systems rapidly and reliably.\n","\n","Benefits of MLOps include shorter development cycles, improved collaboration, increased reliability and performance, and streamlined operational processes. \n","\n","The passage concludes by introducing the MLOps lifecycle and individual capabilities.\n","--------------------------------------------------------------------------------\n","\n","ðŸ“„ **Page 6 Summary:**\n","## Concise Summary\n","\n","This text describes the key elements of building an ML-enabled system, highlighting the interconnected nature of data engineering, ML engineering, and application engineering. \n","\n","**Key Points:**\n","\n","* **Data Engineering:** Crucial for preparing data for analytics and ML tasks. Success in data engineering can lead to successful downstream projects.\n","* **ML Models:** Built and deployed using curated data. They support various applications, including business intelligence, line of business applications, and embedded systems.\n","* **Integration:** Integrating ML models into applications requires ensuring effective use and monitoring performance. \n","* **Monitoring:** Business KPIs should be monitored to understand the impact of ML models on the business.\n","\n","\n","This summary captures the essential points of the text regarding building ML-enabled systems. \n","\n","--------------------------------------------------------------------------------\n","\n","ðŸ“„ **Page 7 Summary:**\n","## Concise Summary of the MLOps Lifecycle\n","\n","The MLOps lifecycle consists of seven iterative processes, encompassing the entire machine learning workflow from development to deployment. \n","\n","These processes include:\n","\n","1. **ML Development:** Building a robust and reproducible model training pipeline.\n","2. **Training Operationalization:** Automating the packaging, testing, and deployment of the training pipeline.\n","3. **Continuous Training:** Regularly re-executing the training pipeline with new data, code changes, or schedule adjustments.\n","4. **Model Deployment:** Packaging, testing, and deploying the trained model for online experimentation and production serving.\n","\n","This iterative approach allows for continuous improvement and optimization of the machine learning model over time.\n","\n","--------------------------------------------------------------------------------\n","\n","ðŸ“„ **Page 8 Summary:**\n","## Concise Summary:\n","\n","MLOps is an end-to-end workflow that encompasses **prediction serving**, **continuous monitoring**, and **data and model management**. This workflow emphasizes control flow and key inputs/outputs, allowing flexibility for skipping or repeating processes.\n","\n","**Key Activities:**\n","\n","* **Experimentation:** Data scientists and researchers prototype models, create labeled datasets, and utilize features governed by data and model management.\n","* **Prediction Serving:** Deploys the trained model for inference in production.\n","* **Continuous Monitoring:** Tracks the model's effectiveness and efficiency.\n","* **Data and Model Management:** Provides centralized governance for auditability, traceability, compliance, shareability, reusability, and discoverability of ML assets. \n","\n","--------------------------------------------------------------------------------\n","\n","ðŸ“„ **Page 9 Summary:**\n","To effectively implement the key MLOps processes, organizations need to establish a set of core technical capabilities. These capabilities can be provided by a single integrated ML platform. Alternatively, they can be created by combining vendor tools that each are best suited to particular tasks, developed as custom services, or created as a combination of these approaches. In most cases, the processes are deployed in stages rather than all at once in a single deployment. An organizationâ€™s plan for adopting these processes and capabilities should align with business priorities and with the organizationâ€™s technical and skills maturity. For example, many organizations start by focusing on the processes for ML development, model deployment, and prediction serving. For these organizations, continuous training and continuous monitoring might not be necessary if they are piloting a relatively small number of ML systems. Figure 4 shows the core set of technical capabilities that are generally required for MLOps. They are abstracted as functional components that can have many-to-many mappings to specific products and technologies.\n","--------------------------------------------------------------------------------\n","\n","ðŸ“„ **Page 10 Summary:**\n","## Concise Summary:\n","\n","This text describes the technical capabilities needed to support Machine Learning (ML) workflows. These capabilities are divided into three categories:\n","\n","1. **Foundational Capabilities**: These include a reliable and scalable compute infrastructure, potentially spanning multiple clouds or on-premises systems. Ideally, this would also include specialized ML accelerators.\n","2. **Configuration Management and CI/CD**: Standardized capabilities are needed to build, test, release, and operate software systems, including ML systems, quickly and reliably.\n","3. **Core MLOps Capabilities**: These include a range of specific ML functions such as experimentation, data processing, model training and evaluation, serving, online experimentation, monitoring, pipelines, and registries.\n","4. **Cross-Cutting Capabilities**: These enable integration and interaction across the ML workflow and include repositories for ML metadata and artifacts, as well as datasets and features.\n","\n","The text also includes a figure (Figure 4) that visually represents the core MLOps technical capabilities. \n","\n","--------------------------------------------------------------------------------\n","\n"]}],"source":["# Print the first 10 summaries in a structured format\n","print(\"\\nðŸ“œ **Extracted Summaries from PDF:**\\n\")\n","for i, summary in enumerate(initial_summary[:10]):\n","    print(f\"ðŸ“„ **Page {i+1} Summary:**\\n{summary}\\n{'-'*80}\\n\")"]},{"cell_type":"markdown","metadata":{"id":"3L_CepRfJrmF"},"source":["The number of characters in the initial summary will be counted to determine if it fits within the prompt's limitations."]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2RZMH6AJsLD","outputId":"afd8f287-1877-43cb-cd2d-aadf888ddff6","executionInfo":{"status":"ok","timestamp":1740078912713,"user_tz":420,"elapsed":42,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["30664"]},"metadata":{},"execution_count":41}],"source":["len(\"\\n\".join(initial_summary))"]},{"cell_type":"markdown","metadata":{"id":"skEnY3SvKRg_"},"source":["Since a prompt previously accommodated 30,000 characters, this summary, having fewer characters, can also be input directly into a prompt. This will be done in the next step."]},{"cell_type":"markdown","metadata":{"id":"c6GKQNAgNyFU"},"source":["**Reduce Step**\n","\n","A reduce function will be created to concatenate the summaries generated in the initial summarization step (Map step) and then apply the final prompt template to produce a more concise summary."]},{"cell_type":"code","execution_count":48,"metadata":{"id":"ONGa0JykJwmW","executionInfo":{"status":"ok","timestamp":1740078992501,"user_tz":420,"elapsed":2,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[],"source":["# Define a function to create a summary of the summaries\n","def reduce(initial_summary, prompt_template):\n","    # Concatenate the summaries from the inital step\n","    concat_summary = \"\\n\".join(initial_summary)\n","\n","    # Create a prompt for the model using the concatenated text and a prompt template\n","    prompt = prompt_template.format(text=concat_summary)\n","\n","    # Generate a summary using the model and the prompt\n","    summary = model_with_limit_and_backoff(prompt)\n","\n","    return summary"]},{"cell_type":"markdown","metadata":{"id":"HG-geUgCN9kX"},"source":["Now, the next step involves **combining all summaries** into a more concise version using the **final prompt template** and the previously created function."]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lWbm1lPAOaaJ","outputId":"1985e38d-eb14-4449-b264-c47227c49cc4","executionInfo":{"status":"ok","timestamp":1740078999635,"user_tz":420,"elapsed":5988,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["## Concise Summary:\n","**Key points:**\n","* This document provides an overview of MLOps (Machine Learning Operations) and its importance for effective model development and deployment.\n","* Key MLOps capabilities include automated and streamlined model building, data and model management, continuous training, model deployment, and performance monitoring.\n","* MLOps facilitates continuous improvement, collaboration, reliability, and faster development cycles for ML systems.\n","* It targets technology leaders, enterprise architects, and ML teams.\n","\n","\n","## Summary of MLOps Process and Stages:\n","* MLOps lifecycle involves seven iterative processes, covering the entire ML workflow.\n","* This includes: ML Development, Training Operationalization, Continuous Training, Model Deployment, Prediction Serving, Online Experimentation, Monitoring, Data & Model Management.\n","\n","\n","## Summary of Key MLOps Capabilities:\n","* Experimentation: Collaborative data exploration, modular source code, experiment tracking, analysis and visualization, integration with ML services\n","* Data Processing: Large-scale data preparation, interactive execution, data connectors, rich transformations, scalable processing for training/serving\n","* Model Training: Efficient training for diverse ML algorithms, common framework support, distributed training with scaling, accelerators, hyperparameter tuning, AutoML\n","* Model Serving: Low latency online prediction and high throughput batch prediction, serving framework support, composite routines, accelerator integration\n","* Model Management and Monitoring: Explainability, prediction logging, online experimentation, model monitoring and efficiency tracking, ML pipelines and model registry\n","* Dataset & Feature Management: Unifies definition and storage, enables sharing, discoverability, reuse, data consistency for training/inference\n","* Continuous Training Pipeline: Enables retraining with new data and code changes, tracks artifacts, integrates data from experimentation, configurable deployment\n","\n","\n"]}],"source":["# Use defined `reduce` function to summarize the summaries\n","summary = reduce(initial_summary, final_prompt_template)\n","\n","print(summary)"]},{"cell_type":"markdown","metadata":{"id":"J1vFUVQnPBQA"},"source":["Recap\n","\n","The entire paper was successfully summarized into a few bullet points using the MapReduce method. Below are its advantages and limitations:\n","Pros:\n","\n","âœ” Capable of summarizing large documents efficiently.\n","âœ” Supports parallel processing, as each page is summarized independently.\n","Cons:\n","\n","âœ– Requires multiple model calls, increasing computational cost.\n","âœ– Loss of context between pages since each is processed separately."]},{"cell_type":"markdown","metadata":{"id":"NAfXxEVKPSZD"},"source":["### **Next Section**  \n","\n","In the following section, an alternative method will be explored, which processes **multiple chunks (pages) per prompt** to generate a more comprehensive summary."]},{"cell_type":"markdown","metadata":{"id":"cWD2fZ5CPXHf"},"source":["**Method 3: MapReduce with Overlapping Chunks**\n","\n","### **Overview of the Method: Overlapping Chunks**  \n","\n","This approach is similar to **MapReduce** but introduces a key improvement: **overlapping chunks**. Instead of summarizing each page independently, multiple pages are grouped and summarized together. This technique helps **preserve context** and **retain more information between chunks**, leading to **more accurate summaries**.  \n","\n","However, combining multiple chunks may sometimes **exceed the model's token limit**. If this happens, possible solutions include:  \n","- **Using a chunk-splitting method** to divide the text more efficiently.  \n","- **Removing some initial chunks** strategically to stay within the token limit."]},{"cell_type":"markdown","metadata":{"id":"JgtEgLRpQRWT"},"source":["**Map Step**\n","\n","In this section, the PDF file will be processed again, and the model will be used to summarize multiple pages together rather than individually. The initial prompt template defined earlier will be applied to generate summaries while preserving context across pages."]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uz5UPugRPB1o","outputId":"8f76bff8-db7e-4582-c716-e843e8dafd9b","executionInfo":{"status":"ok","timestamp":1740079013707,"user_tz":420,"elapsed":497,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:00<00:00, 87.81it/s]\n"]}],"source":["# Read the PDF file and create a list of pages\n","reader = PyPDF2.PdfReader(pdf_file)\n","pages = reader.pages\n","\n","# Create an empty list to store the extracted text from the pages\n","text_from_pages = []\n","\n","# Iterate over the pages and generate a summary for each page\n","for page in tqdm(pages):\n","    # Extract the text from the page and remove any leading or trailing whitespace\n","    text = page.extract_text().strip()\n","\n","    # Append the extracted text to the list of extracted text\n","    text_from_pages.append(text)"]},{"cell_type":"markdown","metadata":{"id":"8qXCEfKXQjPH"},"source":[" **Defining Chunk Size and Summarizing Chunks**  \n","\n","In this step, the **chunk size** (number of pages to be combined per summary) will be specified. The model will then process and summarize each chunk using the predefined prompt template, ensuring that multiple pages are summarized together while maintaining context."]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CMRp7vUzQY8g","outputId":"c6476154-18e8-4099-b58a-f349cb54b23c","executionInfo":{"status":"ok","timestamp":1740079154521,"user_tz":420,"elapsed":108808,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [01:48<00:00,  2.94s/it]\n"]}],"source":["CHUNK_SIZE = 2  # number of overlapping pages\n","\n","# Read the PDF file and create a list of pages\n","reader = PyPDF2.PdfReader(pdf_file)\n","pages = reader.pages\n","\n","# Create an empty list to store the summaries\n","initial_summary = []\n","\n","# Iterate over the pages and generate a summary for a few pages as one chunk based on `CHUNK_SIZE`\n","for i in tqdm(range(len(pages))):\n","    # Select a list of pages to merge as one chunk\n","    pages_to_merge = [x for x in range(i, i + CHUNK_SIZE) if x < len(pages)]\n","\n","    extracted_texts = [text_from_pages[x] for x in pages_to_merge]\n","\n","    # Concatenate the\n","    text = \"\\n\".join(extracted_texts)\n","\n","    # Create a prompt for the model using the concatenated text and a prompt template\n","    prompt = initial_prompt_template.format(text=text)\n","\n","    # Generate a summary using the model and the prompt\n","    summary = model_with_limit_and_backoff(prompt)\n","\n","    # Append the summary to the list of summaries\n","    initial_summary.append(summary)\n","\n","    # If the last page is reached, break the loop\n","    if pages_to_merge[-1] == len(reader.pages):\n","        break\n"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SVYm34coQtzP","outputId":"ea6fc13f-0742-498d-8d0c-87333f15afa9","executionInfo":{"status":"ok","timestamp":1740079160129,"user_tz":420,"elapsed":29,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["## Concise Summary of MLOps Practitioner's Guide:\n","\n","**Focus:** Implementing MLOps framework for continuous delivery and automation of machine learning \n","\n","**Key Highlights:**\n","\n","* **MLOps Lifecycle:** Defines and breaks down the stages to build an ML-enabled system.\n","* **MLOps Capabilities:** Covers essential areas like experimentation, data processing, model training, evaluation, serving, monitoring, etc.\n","* **Key Stages:** Includes guidance on development, training operationalization, deployment, prediction serving, and monitoring.\n","* **Additional Resources:** Provides references for deep understanding.\n","\n","\n","**Overall:** A valuable resource for practitioners to implement robust and efficient MLOps workflows.\n","\n","## Concise Summary of ML-Ops Lifecycle and Capabilities\n","\n","**ML-Ops** is a set of standardized processes and technologies for building, deploying, and operationalizing machine learning (ML) systems rapidly and reliably. It aims to address the unique complexities of ML applications and improve collaboration, reliability, scalability, and development cycle time. \n","\n","This document provides an overview of the ML-Ops lifecycle, core capabilities, and deep dives into specific processes. It targets technology leaders, enterprise architects, and teams involved in building and operationalizing ML systems.\n","\n","### Key Highlights\n","\n","* **ML-Ops Lifecycle:** Covers the stages from building an ML-enabled system to continuous monitoring.\n","* **Core Capabilities:** Includes experimentation, data processing, training, evaluation, serving, online experimentation, monitoring, pipelines, registries, and data/feature/ML metadata tracking.\n","* **Benefits:** Improved collaboration, model reliability and scalability, and shorter development cycles, leading to increased innovation and business value from ML investments.\n","\n","### Document Structure\n","\n","* Part 1: Overview of ML-Ops lifecycle (for all readers)\n","* Part 2: Deep dive into ML-Ops processes and capabilities (for technical details)\n","\n","**Assumptions:** Readers have basic knowledge of ML and development/deployment practices (CI/CD). \n","\n","\n","## MLOps: A Framework for Building and Operationalizing ML Systems\n","\n","**MLOps** is a set of standardized processes and technologies for building, deploying, and operationalizing machine learning (ML) systems. \n","\n","**Key Points:**\n","\n","* **Addresses the unique complexities of ML engineering.**\n","* **Scales and automates ML pipelines.**\n","* **Improves collaboration, reliability, and development cycle times.**\n","* **Drives innovation and business value.**\n","\n","**Target Audience:**\n","\n","* Technology leaders\n","* Enterprise architects\n","* Teams building and operationalizing ML systems\n","\n","**Document Structure:**\n","\n","* Part 1: Overview of the MLOps lifecycle and core capabilities.\n","* Part 2: Deep dive on MLOps processes and capabilities.\n","\n","**Key Challenges Addressed:**\n","\n","* Manual and one-off work.\n","* Lack of reusable components.\n","* Difficulties in handoffs between data scientists and IT.\n","* Talent and integration issues.\n","* Deployment, scaling, and versioning challenges.\n","* Lack of change-management processes.\n","* Governance gaps.\n","\n","**Benefits of Adopting MLOps:**\n","\n","* Streamlined and automated ML process.\n","* Risk management at scale.\n","* Alignment with business goals.\n","* Faster innovation and greater business value.\n","\n","**Additional Notes:**\n","\n","* Readers are assumed to be familiar with basic ML concepts and development/deployment practices.\n","* Organizations can use the MLOps framework to identify gaps and focus on specific areas based on their business context.\n","\n","## Concise Summary\n","\n","This document discusses the challenges and benefits of deploying Machine Learning (ML) systems at scale. It emphasizes the importance of using a standardized framework like MLOps to streamline the ML process, ensuring successful deployment and effective operations.\n","\n","**Key Points:**\n","\n","* **Challenges of ML Deployment:**\n","    * Low success rate in moving beyond pilot stages.\n","    * High manual effort and lack of reusability.\n","    * Talent and integration issues.\n","    * Difficulty in scaling and versioning.\n","* **Benefits of MLOps:**\n","    * Streamlines the ML development process.\n","    * Reduces risk and ensures alignment with business goals.\n","    * Improves collaboration and efficiency.\n","    * Enhances reliability, performance, and scalability.\n","    * Increases ROI of ML projects.\n","* **MLOps Lifecycle:**\n","    * Emphasizes automating key steps of ML system construction.\n","    * Provides standardized processes and technology capabilities.\n","    * Helps manage risk and ensure compliance.\n","* **MLOps vs. DevOps/DataOps:**\n","    * DevOps/DataOps focus on application and data engineering.\n","    * MLOps specifically addresses ML model deployment and operationalization challenges.\n","\n","This summary highlights the crucial role of MLOps in overcoming challenges and realizing the full potential of ML at scale. \n","\n","\n","## Concise Summary\n","\n","This document describes the importance of ML engineering for building and operationalizing machine learning (ML) systems. It introduces MLOps, a methodology that unifies ML system development and operations, providing standardized processes and technology for rapid and reliable deployment. \n","\n","Here are the key takeaways:\n","\n","* **ML Engineering:** Essential for developing and operationalizing ML systems, addressing challenges like data preparation, model tracking, and fairness.\n","* **MLOps:** A methodology for ML engineering, unifying development and operations through standardized processes and technology.\n","* **Benefits of MLOps:** Shorter development cycles, improved collaboration, increased reliability, performance, scalability, and security.\n","* **Building ML-enabled Systems:** A multifaceted undertaking combining data engineering, ML engineering, and application engineering tasks.\n","* **Data Engineering:** Crucial for ingesting, integrating, curating, and refining data for various tasks.\n","* **ML Models:** Built and deployed using curated data, integrated with various applications for supporting business intelligence, line of business applications, and other systems.\n","\n","**Overall, the document emphasizes the importance of ML engineering and MLOps for successfully building and deploying ML-enabled systems.** \n","\n","\n","## Concise Summary\n","\n","This excerpt discusses the importance of data engineering in building ML-enabled systems. It emphasizes that data plays a crucial role in powering both applications and ML models, and that strong data engineering processes are essential for successful downstream tasks.\n","\n","The excerpt also highlights the key aspects of the MLOps lifecycle, including:\n","\n","- **ML development**: Building and testing the training pipeline\n","- **Training operationalization**: Automating and packaging the training process\n","- **Continuous training**: Regularly retraining the model\n","- **Model deployment**: Packaging and deploying the model for online use\n","\n","\n","## Concise Summary of the MLOps Lifecycle\n","\n","**MLOps encompasses 8 key processes for managing and automating the machine learning workflow.** These include:\n","\n","1. **ML development:** Experimenting and building a robust model training process.\n","2. **Training operationalization:** Automating the packaging and deployment of reliable training pipelines.\n","3. **Continuous Training:** Re-running training pipelines based on new data, code changes or schedules.\n","4. **Model Deployment:** Packaging, testing, and deploying models for online serving.\n","5. **Prediction serving:**  Serving models in production environments.\n","6. **Continuous monitoring:**  Monitoring model effectiveness and efficiency in production.\n","7. **Data & model Management:** Governing ML artifacts for auditing, traceability, compliance, reusability, and discoverability.\n","\n","**MLOps workflow:**\n","\n","- **Figure 2** illustrates the 7 integrated and iterative MLOps processes.\n","- **Figure 3** depicts a simplified workflow showing the interaction between these processes, highlighting their flexibility (non-sequential, skipping/repeating phases) and key input/output relationships.\n","\n","This summary captures the main points of the text regarding the various stages and overarching process flow within the MLOps lifecycle.\n","\n","\n","## Concise Summary:\n","\n","MLOps outlines an end-to-end workflow for ML, encompassing development, training, deployment, monitoring, and continuous improvement. Key processes include:\n","\n","**1. Experimentation:** Data scientists and researchers refine models and training routines, generating labeled datasets and reusable artifacts.\n","\n","**2. Training:** Successful models are operationalized as training pipelines, built and deployed using CI/CD.\n","\n","**3. Continuous Training:** Pipelines retrain models based on new data, model decay, and other triggers.\n","\n","**4. Model Management:** Registered models are annotated, reviewed, and deployed.\n","\n","**5. Prediction Serving:** Deployed models serve predictions in online, batch, or streaming formats, generating explanations and serving logs for monitoring.\n","\n","**6. Continuous Monitoring:** Models are monitored for effectiveness and efficiency, detecting decay and optimizing performance.\n","\n","**MLOps Capabilities:** Core technical capabilities, such as data and model management, continuous integration/continuous delivery (CI/CD), and serving infrastructure, are crucial for implementing these processes.\n","\n","**Adoption:** Organizations can adopt MLOps processes and capabilities in stages, aligning with business priorities and technical maturity.\n","\n","\n","## Concise Summary:\n","\n","The document outlines the key steps involved in Machine Learning Operations (MLOps), focusing on the continuous training and deployment of models. It highlights the importance of establishing technical capabilities to support these processes, including both foundational infrastructure and specialized MLOps tools.\n","\n","Here's a breakdown of the key points:\n","\n","**MLOps Processes:**\n","\n","1. **Formalized training procedure:** This includes data preprocessing, model architecture, and training settings.\n","2. **Continuous training pipeline:** This automatically retrains models with new data or when performance degrades.\n","3. **Model management:** This tracks and approves models for release.\n","4. **Model deployment:** This involves deploying models to production environments for serving predictions.\n","5. **Continuous monitoring:** This monitors model performance and efficiency.\n","\n","**MLOps Capabilities:**\n","\n","1. **Foundational capabilities:** These include reliable compute infrastructure, configuration management, and CI/CD pipelines.\n","2. **Core MLOps capabilities:** These include tools for experimentation, data processing, model training, evaluation, serving, monitoring, and management.\n","3. **Cross-cutting capabilities:** These include ML metadata and artifact repositories, and ML dataset and feature repositories.\n","\n","**Key Takeaways:**\n","\n","* MLOps enables efficient and reliable deployment of ML models.\n","* It requires a combination of foundational and specialized capabilities.\n","* Organizations can adopt MLOps processes and capabilities in stages, aligning with their priorities and maturity.\n","\n","## Additional Notes:\n","\n","* The document also mentions the importance of data and concept drift, which refers to changes in data patterns that can affect model performance over time.\n","* The diagram in Figure 4 provides a visual representation of the core MLOps technical capabilities. \n","\n","\n","## Concise Summary of MLOps Technical Capabilities\n","\n","This text describes the essential technical capabilities needed for successful MLOps implementation. \n","\n","**Foundational Capabilities:**\n","\n","* Reliable, scalable, and secure compute infrastructure.\n","* Advanced capabilities such as specialized ML accelerators.\n","* Standardized configuration management and CI/CD pipelines.\n","\n","**Core MLOps Capabilities:**\n","\n","* Experimentation\n","* Data Processing\n","* Model Training\n","* Model Evaluation\n","* Model Serving\n","* Online Experimentation\n","* Model Monitoring\n","* ML Pipeline\n","* Model Registry\n","\n","**Cross-Cutting Capabilities:**\n","\n","* ML Metadata and Artifact Repository\n","* ML Dataset and Feature Repository\n","\n","**Detailed Descriptions:**\n","\n","The document provides detailed descriptions of each MLOps capability, outlining their key functionalities and functionalities. It covers aspects like:\n","\n","* Experimentation environments and version control integration.\n","* Data processing for ML development and production.\n","* Model training efficiency and cost-effectiveness. \n","\n"]}],"source":["print(\"\\n\\n\".join(initial_summary[:10]))"]},{"cell_type":"markdown","metadata":{"id":"sbp9EQCgQ9ce"},"source":["### **Reduce Step**  \n","\n","The next step involves **combining all generated summaries** into a more concise version using the **final prompt template** and the previously implemented function. This step further refines the summary while preserving key information."]},{"cell_type":"code","execution_count":53,"metadata":{"id":"MXFy1m8LQxBN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740079171907,"user_tz":420,"elapsed":4479,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}},"outputId":"9cfb267b-bc48-405d-e369-ee0a6cb93792"},"outputs":[{"output_type":"stream","name":"stdout","text":["I am ready to provide summaries in bullet points, when you are. \n","\n"]}],"source":["# Use defined `reduce` function to summarize the summaries\n","summary = reduce(initial_summary, final_prompt_template)\n","\n","print(summary)"]},{"cell_type":"markdown","metadata":{"id":"Ajh9eZBlRQ3O"},"source":["### **Recap**  \n","\n","The model successfully summarized the entire paper into a few bullet points using the **MapReduce with Overlapping Chunks** method. Below are the advantages and limitations of this approach:  \n","\n","#### **Pros:**  \n","âœ” **Capable of summarizing large documents** efficiently.  \n","âœ” **Preserves context** between pages by summarizing sequential pages together.  \n","âœ” **Supports parallel processing**, as summaries are generated independently.  \n","\n","#### **Cons:**  \n","âœ– **Requires multiple model calls**, increasing processing overhead.  \n","âœ– **Slightly slower** than the standard MapReduce method.  \n","âœ– **Produces larger input text**, which may approach the modelâ€™s token limit."]},{"cell_type":"markdown","metadata":{"id":"Bp7IqDy8ReaG"},"source":["### **Next Section**  \n","\n","In the upcoming section, a different approach will be explored, where **only the summary from the previous page** is used instead of the full text. This method helps retain context across pages while reducing the input size for the model."]},{"cell_type":"markdown","metadata":{"id":"5g0xcGaZRyIe"},"source":["### **Method 4: MapReduce with Rolling Summary (Refine)**  \n","\n","In some cases, summarizing multiple pages together may exceed the modelâ€™s token limit. To address this, a **rolling summary approach** will be used.  \n","\n","Instead of summarizing chunks independently, this method takes **the summary from the previous step** along with the **next page** to generate a refined summary. This ensures that each prompt retains **context from the previous page**, leading to a more **coherent and accurate** final summary."]},{"cell_type":"code","execution_count":55,"metadata":{"id":"NThryLHuRRz5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740079428876,"user_tz":420,"elapsed":81983,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}},"outputId":"baee8253-b83e-4e2b-aa44-50a736e3549b"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [01:21<00:00,  2.21s/it]\n"]}],"source":["initial_prompt_template = \"\"\"\n","    Taking the following context delimited by triple backquotes into consideration:\n","\n","    ```{context}```\n","\n","    Write a concise summary of the following text delimited by triple backquotes.\n","\n","    ```{text}```\n","\n","    CONCISE SUMMARY:\n","\"\"\"\n","\n","\n","# Read the PDF file and create a list of pages.\n","reader = PyPDF2.PdfReader(pdf_file)\n","pages = reader.pages\n","\n","# Create an empty list to store the summaries.\n","initial_summary = []\n","\n","# Iterate over the pages and generate a summary\n","for idx, page in enumerate(tqdm(pages)):\n","    # Extract the text from the page and remove any leading or trailing whitespace.\n","    text = page.extract_text().strip()\n","\n","    if idx == 0:  # if current page is the first page, no previous context\n","        prompt = initial_prompt_template.format(context=\"\", text=text)\n","\n","    else:  # if current page is not the first page, previous context is the summary of the previous page\n","        prompt = initial_prompt_template.format(\n","            context=initial_summary[idx - 1], text=text\n","        )\n","\n","    # Generate a summary using the model and the prompt\n","    summary = model_with_limit_and_backoff(prompt)\n","\n","    # Append the summary to the list of summaries\n","    initial_summary.append(summary)\n"]},{"cell_type":"markdown","metadata":{"id":"iXdm_uO8SPmg"},"source":["### **Listing Initial Summary Entries**  \n","\n","In this step, a few entries from the **initial summary list** will be displayed. This provides a reference for how the summaries have been generated so far and helps in understanding the progression of information before applying the rolling summary approach."]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V_HozLl0SQIE","outputId":"fb440488-4418-4525-b090-f16795fdf047","executionInfo":{"status":"ok","timestamp":1740079433477,"user_tz":420,"elapsed":19,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['## Concise Summary:\\n\\n**MLOps: A Framework for Continuous Delivery and Automation of Machine Learning**\\n\\nThis white paper, published in May 2021, by Khalid Salama, Jarek Kazmierczak, and Donna Schut, provides a guide for practitioners on MLOps, a framework for continuous delivery and automation of machine learning. \\n',\n"," '## Concise Summary:\\n\\nThis white paper explores **MLOps**, a framework for continuous delivery and automation of machine learning (ML) workflows. \\n\\nThe text outlines the **MLOps lifecycle** and its core capabilities, including:\\n\\n* **ML development:** Design, implementation, and testing of ML models.\\n* **Training operationalization:** Automating model training and deployment.\\n* **Continuous training:** Updating models with fresh data.\\n* **Model deployment:** Serving models for online predictions.\\n* **Continuous monitoring:** Tracking model performance and data quality.\\n* **Data and model management:** Organizing and governing data and models.\\n\\n The document covers various MLOps processes like experimentation, data processing, model evaluation, serving, and monitoring. It also emphasizes the significance of ML pipelines, model registries, and metadata tracking. \\n\\nOverall, the text provides a comprehensive guide to implementing MLOps for efficient and reliable ML development and deployment. \\n',\n"," '## Concise Summary:\\n\\nThis executive summary introduces MLOps, a framework for building and operationalizing machine learning (ML) systems efficiently and reliably. It highlights the need for standardized processes and technology in the context of ML engineering, similar to DevOps and DataOps for software and data engineering.\\n\\nThe document draws upon Google Cloud\\'s AI Adoption Framework, emphasizing the \"scale\" and \"automate\" themes. It outlines an MLOps framework with core processes and technical capabilities, aimed at improving collaboration, reliability, scalability, and development cycle times for ML systems.\\n\\nThe target audience includes technology leaders, enterprise architects, and teams seeking to understand MLOps in practice. Familiarity with basic ML concepts and development/deployment practices like CI/CD is assumed.\\n\\nThe first part provides an overview of the MLOps lifecycle, while the second part delves deeper into specific processes and capabilities. \\n',\n"," '## Concise Summary:\\n\\nThe provided text highlights the challenges organizations face in deploying and operationalizing machine learning (ML) models effectively. The key issues include:\\n\\n* **Limited scaling**: Only half of organizations move beyond pilot stages, and many struggle to scale successful deployments.\\n* **Lack of automation**: Manual and one-off work, coupled with non-reusable components, hinder efficiency.\\n* **Integration issues**: Difficulties in handoffs and lack of alignment with DataOps and DevOps practices impede progress.\\n* **Talent shortage**: The lack of mid- to senior-level talent poses a significant obstacle.\\n* **Governance challenges**: Lack of strong governance models hinders scalability.\\n\\nThe text emphasizes the need for an automated and streamlined MLOps process to address these challenges. This process will not only facilitate successful deployments but also ensure that ML applications continue to align with business goals and operate effectively in changing environments.',\n"," '## Concise Summary:\\n\\nThis text offers insights into Machine Learning Operations (MLOps) and its role in ML model effectiveness. Key points include:\\n\\n* **ML Engineering**: Crucial for building production-grade ML systems, requires managing complexities like data preparation, performance monitoring, and model retraining.\\n* **MLOps**: Methodology for unifying ML development and operations, automating critical steps for efficient deployment and management.\\n* **Benefits**: Shorter development cycles, improved collaboration, increased reliability, and streamlined operations for better ROI.',\n"," '## Concise Summary:\\n\\nThis text highlights the multifaceted nature of building ML-enabled systems, emphasizing the interconnected roles of data engineering, ML engineering, and application engineering. \\n\\nIt underscores the importance of data engineering in providing high-quality data for both analytics and ML tasks. Additionally, it emphasizes the crucial role of integrating ML models into applications, ensuring effective usage and performance monitoring. \\n\\nThe text concludes by stressing the importance of monitoring relevant business KPIs to evaluate the impact of ML models on the business and make necessary adaptations. \\n',\n"," '## Concise Summary:\\n\\nThe MLOps lifecycle outlines seven iterative processes:\\n\\n* **ML Development:** Creating and refining a robust, reproducible model training procedure.\\n* **Training Operationalization:** Automating the training pipeline for reliability and repeatability.\\n* **Continuous Training:** Re-running the training pipeline with new data, code changes, or scheduling.\\n* **Model Deployment:** Packaging, testing, and deploying models for online experimentation and production. \\n\\nThese processes work together to ensure effective development, deployment, and continuous improvement of ML models. \\n',\n"," '## Concise Summary:\\n\\n**Prediction Serving:** Deployed models are served for data inference in production environments.\\n\\n**Continuous Monitoring:** Deployed model performance and efficiency are continuously monitored.\\n\\n**Data and Model Management:** Centralized management of all ML assets ensures auditability, traceability, and compliance while promoting sharing and reuse. \\n',\n"," '## Concise Summary\\n\\nThis section focuses on the operationalization and deployment of machine learning (ML) models, including the following key steps:\\n\\n1. **Formalized Training Procedure:**  This defines the training process, including data preprocessing, model architecture, and training settings. For continuous training systems, this is operationalized as a training pipeline.\\n2. **Continuous Training Pipeline:** This process automatically retrains the model using new data or when performance degradation is detected. \\n3. **Model Management:** Trained models are registered, annotated, and reviewed for approval before deployment. \\n4. **Model Deployment:**  Models are deployed to production environments for prediction serving, either online, in batches, or through streaming.\\n5. **Continuous Monitoring:**  Model performance is monitored for effectiveness and efficiency, detecting issues like performance decay and resource utilization.\\n6. **Core Technical Capabilities:** Implementing these processes requires specific technical capabilities, provided by integrated ML platforms, vendor tools, custom services, or a combination thereof.\\n\\nThe adoption of these processes and capabilities should be staged and aligned with business priorities and technical maturity. Organizations can start by focusing on development, deployment, and serving, adding continuous training and monitoring as needed. \\n',\n"," '## Concise Summary\\n\\nThis section defines the core technical capabilities required for MLOps success. \\n\\n**Foundational Capabilities:**\\n* Reliable, scalable, and secure compute infrastructure (potentially leveraging existing on-premises and cloud resources)\\n* Standardized configuration management and CI/CD for rapid and reliable software operation\\n\\n**Core MLOps Capabilities:**\\n* Experimentation, data processing, model training, evaluation, serving, online experimentation, monitoring, pipelines, and registry\\n* ML metadata and artifact repository for integration and interaction\\n* ML dataset and feature repository for collaborative data access\\n\\n**Staged Adoption:**\\nStart with development, deployment, and serving, adding continuous training and monitoring as needed.\\n']"]},"metadata":{},"execution_count":56}],"source":["initial_summary[:10]"]},{"cell_type":"markdown","metadata":{"id":"zYHXMr42Sshh"},"source":["Handling Duplicate Entries\n","\n","Since the rolling summary approach carries over context from previous pages, some duplicate entries in the summary list are expected. These duplicates can be easily removed by using the set() function, which ensures that only unique summaries are retained."]},{"cell_type":"code","execution_count":57,"metadata":{"id":"GZOdPQhVSUVb","executionInfo":{"status":"ok","timestamp":1740079446358,"user_tz":420,"elapsed":2,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[],"source":["initial_summary = set(initial_summary)  # set() function removes duplicate items"]},{"cell_type":"markdown","metadata":{"id":"bLe1luAjS8MU"},"source":["### **Reduce Step**  \n","\n","The next step involves **combining all refined summaries** into a more concise version using the **final prompt template** and the previously implemented function. This step ensures that the summary remains **coherent and compact** while preserving key contextual information."]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQChh4PtSveb","outputId":"24225cf0-39cc-49c7-a0ea-f068b38babf8","executionInfo":{"status":"ok","timestamp":1740079456248,"user_tz":420,"elapsed":6607,"user":{"displayName":"Seyed Mahdi Fazeli","userId":"18356712596431782273"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["## Concise Summary of MLOps White Paper:\n","\n","**Key Points:**\n","\n","* **MLOps** is a framework for automating and streamlining the lifecycle of ML models, from development to deployment and monitoring.\n","* **Benefits:** Reduced development time, improved collaboration, increased reliability, better ROI.\n","* **Essential features:** Dataset & feature repository, model registry, ML pipelines, model serving, online experimentation, model monitoring.\n","* **Challenges:** Scaling, automation, integration, talent shortage, governance.\n","* **Key MLOps capabilities:**\n","\n","  * **Experimentation:** Data preparation, model prototyping, validation.\n","  * **Data processing:** Efficient data transformation for ML tasks.\n","  * **Model training:** Continuous training pipelines for updated models.\n","  * **Model deployment:** Packaging, testing, and serving models for online experimentation and production.\n","  * **Model monitoring:** Detecting and addressing issues in prediction serving.\n","* **Additional features:** Cost optimization, model explainability, prediction serving efficiency monitoring, data & model management.\n","* **Staged adoption:** Start with development, deployment, and serving, adding continuous training and monitoring as needed.\n","* **Key tools:** Integrated ML platforms, vendor tools, custom services.\n","* **Success factors:** Reliable infrastructure, standardized configuration management, CI/CD, collaboration, responsible ML implementation.\n","\n","**Additional resources:** Books, guides, courses, articles, videos on MLOps best practices, design patterns, introductions, continuous delivery, architecture, and environment setup. \n","\n"]}],"source":["# Use defined `reduce` function to summarize the summaries\n","summary = reduce(initial_summary, final_prompt_template)\n","\n","print(summary)"]},{"cell_type":"markdown","metadata":{"id":"GeNnUM8RTpjb"},"source":["### **Recap**  \n","\n","The model successfully summarized the entire paper into a few bullet points using the **MapReduce with Rolling Summary** method. Below are the advantages and limitations of this approach:  \n","\n","#### **Pros:**  \n","âœ” **Capable of summarizing large documents** effectively.  \n","âœ” **Preserves context** across pages by incorporating summaries from previous sections.  \n","\n","#### **Cons:**  \n","âœ– **Requires multiple model calls**, increasing processing time.  \n","âœ– **Not suitable for parallel processing**, as each summary depends on the previous one."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}